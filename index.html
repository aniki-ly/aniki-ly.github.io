<!doctype html>
<html lang="en">


<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <title>Yu Lu</title>
    <style type="text/css">
    hr { 
    background-color:black;
    display: block;
    margin-top: 0.5em;
    margin-bottom: 0.5em;
    margin-left: auto;
    margin-right: auto;
    border-style: inset;
    border-width: 1px;
    } 
    img.profile {
	border-radius: 50%;
	width: 85%; 
	height: Auto;
    }
    .center {
        text-align: center;
    }

    .lead {
        font-size: 0.95rem;
        text-align: left;
    }

    .subtitle {
        font-size: 1.7rem;
        text-align: left;
    }

    .title {
        font-size: 2.2rem;
        text-align: left;
    }

    .ttitle {
    font-size: 1.2rem;
    text-align: left;
    }

    </style>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-141257534-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-141257534-1');
    </script>
</head>

<body>
    <div class="container border" style="margin-top:10px;">
        <div class="row">

            <div class="row">
                <div class="col-md-1"></div>
                <div class="col-md-8">
                    <!-- Intro -->
                    <div>
                        <div class="row">
                            <div class="col-sm-5">
                                <img src="images/pic.jpg" alt="" class="figure-img img-fluid profile" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <header>
                                    <h3 class="title">Yu Lu </h3>
                                    <h3 class="ttitle">PhD Student <br/></h3>
                                    University of Technology Sydney (UTS)<br/>
                                    Email: aniki.yulu [AT] gmail dot com<br/>
                                    <div class="links">
                                        <a href='https://scholar.google.com/citations?user=QQUmpsgAAAAJ'>[Google Scholar]</a>
                        <a href='https://github.com/aniki-ly'>[Github]</a>
					    <a href='https://twitter.com/luyu79797018'>[Twitter]</a>

                                    </div>
                                </header>
                            </div>
                        </div>
                    </div>
                    <br/>

                    <div>
                        <!-- <h3 class="subtitle">About Me</h3> -->
                        <p class="lead">
                            Yu Lu (路雨) is a PhD candidate at <a href="http://reler.net/" target="_blank">ReLER Lab</a>, Australian Artificial Intelligence Institute (AAII), University of Technology Sydney (UTS). His academic advisors are <a href="http://reler.net/people/yi_yang/index.html" target="_blank">Prof. Yi Yang</a>. and <a href="http://ffmpbgrnn.github.io/" target="_blank">Dr. Linchao Zhu</a>. He received his M.Eng. degrees from <a href="https://www.bupt.edu.cn/" target="_blank">Beijing University of Posts and Telecommunications</a>. 
<!--                             His research interests include Multi-Modal Understanding and Generation. Now, he focuses on exploring new applications and domains of LLM and Vision Generative models. -->
		            His current research interests encompass the development of multi-modal large language models and exploring video generation techniques.
                        </p>
			    Seeking Research Interns in 2024 [AU/US/Remote], feel free to reach out for opportunities!
                    </div>

                    <!-- Publications -->
                    <!-- About Me -->
                    <!-- <hr> -->
                    <div>
                        <hr>
                        <h3 class="subtitle">Experiences</h3>
                        <div class="row">
                            <div class="col-sm-1">
                                <img src="images/zju.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">Research Visiting: CCAI, Zhejiang University, </span> Jun. 2023 - Sep. 2023<br>
                                    Advisior: <a href="http://reler.net/people/yi_yang/index.html" target="_blank">Pro. Yi Yang</a>
                                </p>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-sm-1">
                                <img src="images/kwai.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">Research Intern: MMU Kwai Tech, </span> September 2021 - March 2022<br>
                                    Advisior: <a href="https://scholar.google.com/citations?user=4nL1cDEAAAAJ&hl=en" target="_blank">Dr. Debing Zhang</a>
                                </p>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-sm-1">
                                <img src="images/Tecent.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">Research Intern: AI Tencent, </span> April 2021 - June 2021<br>
                                    Advisior: <a href="https://scholar.google.com.au/citations?user=QJAr1KoAAAAJ&hl=en" target="_blank">Dr. Yuchen Yuan</a>
                                </p>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-sm-1">
                                <img src="images/baidu.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">Research Intern: IDL Baidu Research, </span> July 2019 - July 2020<br>
                                    Advisior: <a href="http://pages.cs.wisc.edu/~gdguo/" target="_blank">Prof. Guodong Guo</a>
                                </p>
                            </div>
                        </div>

                    </div>



                    <hr>
                    <div>
                        <h3 class="subtitle">Publications</h3>

                        <!-- TMM -->
                        <div class="row">
                            <div class="col-sm-3">
                                <img src="images/FlowZero.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">FlowZero: Zero-Shot Text-to-Video Synthesis with LLM-Driven Dynamic Scene Syntax</span></br>
                                    <span class="font-weight-bold"> Yu Lu</span>, Linchao Zhu, Hehe Fan, Yi Yang</br>
                    <i>Arxiv</i></br>
                                    <a href='http://arxiv.org/abs/2311.15813'>[Paper]</a> 
                                    <a href='https://flowzero-video.github.io/'>[Project]</a>
                                    <a href='https://github.com/aniki-ly/FlowZero'>[Code]</a> 
                                </p>
                            </div>
                        </div>

                        <!-- TIP -->
                        <div class="row">
                            <div class="col-sm-3">
                                <img src="images/TIP.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">Zero-shot Video Grounding with Pseudo Query Lookup and Verification</span></br>
                                    <span class="font-weight-bold"> Yu Lu</span>, Ruijie Quan, Linchao Zhu, Yi Yang</br>
                    <i> IEEE Transactions on Image Processing (TIP) , 2024</i></br>
                                    <a href=''>[Paper]</a> 
                                    <a href=''>[code]</a>
                                </p>
                            </div>
                        </div>

                        <!-- TMM -->
                        <div class="row">
                            <div class="col-sm-3">
                                <img src="images/TMM.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">Show Me a Video: A Large-Scale Narrated Video Dataset for Coherent Story Illustration</span></br>
                                    <span class="font-weight-bold"> Yu Lu</span>, Feiyue Ni, Haofan Wang, Xiaofeng Guo, Linchao Zhu, Zongxin Yang, Ruihua Song, Lele Cheng, Yi Yang</br>
                    <i>IEEE Transactions on MultiMedia (TMM) , 2023</i></br>
                                    <a href='https://ieeexplore.ieee.org/abstract/document/10195243'>[Paper]</a> 
                                    <a href='https://nfy-dot.github.io/CVSV-dataset/'>[Project]</a>
                                </p>
                            </div>
                        </div>

                        <!-- ECLIP -->
                        <div class="row">
                            <div class="col-sm-3">
                                <img src="images/EFLIP.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">ECLIP: Efficient Contrastive Language-Image Pretraining via Ensemble Confidence Learning and Masked Language Modeling</span></br>
                                    Jue Wang, Haofan Wang, Weijia Wu, Jincan Deng, <span class="font-weight-bold"> Yu Lu</span>, Xiaofeng Guo, Debing Zhang </br>
                    <i>ICML 2022 Pre-training Workshop</i></br>
                                    <a href='https://openreview.net/pdf?id=5IFFLY4JR24'>[Paper]</a> 
                                    <a href='https://yulu.net.cn/'>[Code]</a>
                                </p>
                            </div>
                        </div>

                        <!-- CRIS -->
                        <div class="row">
                            <div class="col-sm-3">
                                <img src="images/CRIS.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">CRIS: CLIP-Driven Referring Image Segmentation</span></br>
                                    Zhaoqing Wang*, <span class="font-weight-bold">Yu Lu*</span>, Qiang Li, Xunqiang Tao, Yandong Guo, MingMing Gong, Tongliang Liu (* means equal contribution)</br>
                    <i>CVPR 2022</i></br>
                                    <a href='https://arxiv.org/abs/2111.15174'>[Paper]</a> 
                                    <a href='https://github.com/DerrickWang005/CRIS.pytorch'>[Code]</a>
                                </p>
                            </div>
                        </div>

                        <!-- GINet -->
                        <div class="row">
                            <div class="col-sm-3">
                                <img src="images/GINet.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">GINet: Graph Interaction Network for Scene Parsing</span></br>
                                    Tianyi Wu*, <span class="font-weight-bold"> Yu Lu*</span>, Yu Zhu, Chang Zhang, Ming Wu, Zhanyu Ma, Guodong Guo (* means equal contribution)</br>
                                    <i>ECCV 2020</i></br>
                                    <a href='https://arxiv.org/pdf/2009.06160.pdf'>[Paper]</a> 
				    <a href='https://github.com/PaddlePaddle/PaddleSeg'>[Code]</a>
                                </p>
                            </div>
                        </div>



                        </div>
            <div>
                <hr>
                <h3 class="subtitle">Professional Activities</h3>

                <div class="row">
                    <div class="col" style="margin-top: auto; margin-bottom: auto;">
                        <p class="lead">
                            <span class="font-weight-bold">Journal Review: </span> <br>
                            TPAMI, TIP, KBS
                        </p>
                    </div>
                </div>

                <div class="row">
                    <div class="col" style="margin-top: auto; margin-bottom: auto;">
                        <p class="lead">
                            <span class="font-weight-bold">Conference Review: </span> <br>
                            CVPR, ICCV, ECCV, ACL
                        </p>
                    </div>
                </div>

            </div>


                <div class="col-md-2"></div>
            </div>

            <!-- News -->
            <div class="col" style="background-color:rgb(190, 193, 194);">
                <div class="row"> 
                </div>
                <h1>News</h1><br>
                <font size="3px">	    

            <!--     <b>27 February 2019</b><br>
                <span class="easylink">I am invited to be a local chair of the <a href="http://ccis2018.csp.escience.cn/" target="_blank">CCIS 2019</a> conference, to be held in Singapore on Sep 25-27. 
                </span><br><br> -->
                <b>14 Jun 2022</b><br>
                <span class="easylink">
                  Our paper <A
                  href="papers/CRIS.pdf">"EfficientCLIP: Efficient Cross-Modal Pre-training by Ensemble Confident Learning and Language Modeling"</A> is accepted by ICML Pre-training Workshop.
                </span><br><br>

                <b>4 March 2022</b><br>
                <span class="easylink">
                  Our paper <A
                  href="papers/CRIS.pdf">"CRIS: CLIP-Driven Referring Image Segmentation "</A> is accepted by CVPR2022.
                </span><br><br>

                <b>11 July 2020</b><br>
                <span class="easylink">
                  Our paper <A
                  href="papers/GINet_ECCV.pdf">"GINet: Graph Interaction Network for Scene Parsing "</A> is accepted by ECCV2020.
                </span><br><br>

                <b>4 July 2023</b><br>
                <span class="easylink">
                  Our paper <A
                  href="papers/CRIS.pdf">"Show Me a Video: A Large-Scale Narrated Video Dataset for Coherent Story Illustration "</A> is accepted by TMM2023.
                </span><br><br>
			
                <b>25 Jan 2024</b><br>
                <span class="easylink">
                  Our paper <A
                  href="papers/CRIS.pdf">"Zero-shot Video Grounding with Pseudo Query Lookup and Verification"</A> is accepted by TIP2024.
                </span><br><br>


                </font>

                        </div>


    </div>
    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
</body>

</html>
