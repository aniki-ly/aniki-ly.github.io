<!doctype html>
<html lang="en">


<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <title>Yu Lu</title>
    <style type="text/css">
    hr { 
    background-color:black;
    display: block;
    margin-top: 0.5em;
    margin-bottom: 0.5em;
    margin-left: auto;
    margin-right: auto;
    border-style: inset;
    border-width: 1px;
    } 
    img.profile {
	border-radius: 50%;
	width: 85%; 
	height: Auto;
    }
    .center {
        text-align: center;
    }

    .lead {
        font-size: 0.95rem;
        text-align: left;
    }

    .subtitle {
        font-size: 1.7rem;
        text-align: left;
    }

    .title {
        font-size: 2.2rem;
        text-align: left;
    }

    .ttitle {
    font-size: 1.2rem;
    text-align: left;
    }

    </style>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-141257534-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-141257534-1');
    </script>
</head>

<body>
    <div class="container border" style="margin-top:10px;">
        <div class="row justify-content-center">
            <div class="col-md-10">
                <!-- Intro -->
                <div>
                    <div class="row">
                        <div class="col-sm-5">
                            <img src="images/haofan.jpg" alt="" class="figure-img img-fluid profile" style="margin:10px; width:70%;">
                        </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <header>
                                    <h3 class="title">Yu Lu </h3>
                                    <h3 class="ttitle">Postdoctoral Researcher<br/></h3>
                                    Zhejiang University<br/>
                                    Email: aniki.yulu [AT] gmail dot com<br/>
                                    <div class="links">
                                        <a href='https://scholar.google.com/citations?user=QQUmpsgAAAAJ'>[Google Scholar]</a>
                        <a href='https://github.com/aniki-ly'>[Github]</a>
					    <a href='https://twitter.com/luyu79797018'>[Twitter]</a>
					    <a href='https://www.linkedin.com/in/yu-lu-50413a23a/'>[LinkedIn]</a>
                                    </div>
                                </header>
                            </div>
                        </div>
                    </div>
                    <br/>

                    <div>
                        <!-- <h3 class="subtitle">About Me</h3> -->
                        <p class="lead">
                            Yu Lu (路雨) is a Postdoctoral Researcher at Zhejiang University, where he is leading a small research team that mostly works on video and image generative models. Before that, he obtained his Ph.D. degree at University of Technology Sydney (UTS). His academic advisor is <a href="http://reler.net/people/yi_yang/index.html" target="_blank">Prof. Yi Yang</a>. 
                            In past years, he worked at tech institutions including WeXin Group (Tencent), Kwai Tech, Tencent AI Lab, and Baidu Research.
                        </p>
                        <p class="lead" style="font-style: italic; font-weight: bold;">
                            I'm always open to research discussions and collaborations, please feel free to email me.
                        </p>
                    </div>

                    <!-- Publications -->
                    <!-- About Me -->
                    <!-- <hr> -->
                    <hr>
                    <div>
                        <h3 class="subtitle">News</h3>
                        <ul class="list-group">
                            <li class="list-group-item border-0 py-1"><b>Sep 2025:</b> FlexSelect and ICEdit accepted by NeurIPS 2025!</li>
                            <li class="list-group-item border-0 py-1"><b>July 2025:</b> We have released the paper <a href="https://arxiv.org/pdf/2507.00162">FreeLong++</a> for long video generation with 8x longer extension!</li>
			                <li class="list-group-item border-0 py-1"><b>June 2025:</b> We have released the paper <a href="https://arxiv.org/pdf/2506.00993">FlexSelect</a> for long video understanding with 9x faster than baseline!</li>
                            <li class="list-group-item border-0 py-1"><b>May 2025:</b> We have released the paper <a href="https://arxiv.org/abs/2504.20690">In-context edit</a> for image editing!</li>
                            <li class="list-group-item border-0 py-1"><b>Feb 2025:</b> HarmonySet accepted by CVPR 2025!</li>
                            <li class="list-group-item border-0 py-1"><b>Dec 2024:</b> Paper on Video-Text Retrieval with unlabeled videos accepted by TIP 2024</li>
                            <li class="list-group-item border-0 py-1"><b>Sep 2024:</b> Two papers (FreeLong and AMP) accepted by NeurIPS 2024!</li>
                            <li class="list-group-item border-0 py-1"><b>Sep 2024:</b> Successfully defended Ph.D. thesis <a href="https://opus.lib.uts.edu.au/handle/10453/186243">"Zero-shot Natural Language-Driven Video Analysis and Synthesis"</a></li>
                            <li class="list-group-item border-0 py-1"><b>Jan 2024:</b> Paper on Zero-shot Video Grounding accepted by TIP 2024</li>
                        </ul>
                    </div>


                    <hr>
                    <div>
                        <h3 class="subtitle">Selected Publications</h3>



                        <!-- FreeLong++-->
                        <div class="row">
                            <div class="col-sm-3">
                                <img src="images/FreeLong++.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">FreeLong++: Training-Free Long Video Generation via Multi-band SpectralFusion</span></br>
                                    <span class="font-weight-bold"> Yu Lu</span>, Yi Yang</br>
				    <i>Arxiv</i></br>
                                    <a href='https://arxiv.org/pdf/2507.00162'>[Paper]</a> 
                                    <a href='https://freelongvideo.github.io/'>[Project]</a> 
                                </p>
                            </div>
                        </div>

                        <!-- FlexSelect-->
                        <div class="row">
                            <div class="col-sm-3">
                                <img src="images/flexselect.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">FlexSelect: Flexible Token Selection for Efficient Long Video Understanding</span></br>
                                    Yunzhu Zhang*, <span class="font-weight-bold"> Yu Lu*</span>, Tianyi Wang, Fengyun Rao, Yi Yang, Linchao Zhu</br>
				    <i>NeurIPS 2025</i></br>
                                    <a href='https://arxiv.org/pdf/2506.00993'>[Paper]</a> 
                                    <a href='https://yunzhuzhang0918.github.io/flex_select/'>[Project]</a> 
                                </p>
                            </div>
                        </div>
			    
                        <!-- In-Context Edit -->
                        <div class="row">
                            <div class="col-sm-3">
                                <img src="images/icedit.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer</span></br>
                                    Zechuan Zhang, Ji Xie, <span class="font-weight-bold"> Yu Lu</span>, Zongxin Yang, Yi Yang</br>
				    <i>NeurIPS 2025</i></br>
                                    <a href='https://arxiv.org/abs/2504.20690'>[Paper]</a> 
                                    <a href='https://river-zhang.github.io/ICEdit-gh-pages/'>[Project]</a> 
                                </p>
                            </div>
                        </div>

                        <!-- HarmonySet -->
                        <div class="row">
                            <div class="col-sm-3">
                                <img src="images/harmonyset.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">HarmonySet: A Comprehensive Dataset for Understanding
Video-Music Semantic Alignment and Temporal Synchronization</span></br>
                                    Zitang Zhou, Ke Mei, <span class="font-weight-bold"> Yu Lu <span>&#9993;</span> </span>, Tianyi Wang, Fengyun Rao (<span>&#9993;</span> means corresponding author)</br>
                    <i>CVPR 2025</i></br>
                                    <a href='https://arxiv.org/abs/2503.01725'>[Paper]</a> 
                                    <a href='https://harmonyset.github.io/'>[Project]</a> 
                                </p>
                            </div>
                        </div>


                        <!-- FreeLong -->
                        <div class="row">
                            <div class="col-sm-3">
                                <img src="images/FreeLong.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">FreeLong: Training-Free Long Video Generation with SpectralBlend Temporal Attention</span></br>
                                    <span class="font-weight-bold"> Yu Lu</span>, Yuanzhi Liang, Linchao Zhu, Yi Yang</br>
                    <i>NeurIPS 2024</i></br>
                                    <a href='https://arxiv.org/pdf/2407.19918'>[Paper]</a> 
                                    <a href='https://yulu.net.cn/freelong'>[Project]</a> 
                                    <a href='https://github.com/aniki-ly/FreeLong'>[Code]</a> 
                                </p>
                            </div>
                        </div>

                        <!-- AMP
                        <div class="row">
                            <div class="col-sm-3">
                                <img src="images/AMP.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">Automated Multi-level Preference for MLLMs</span></br>
                                    Mengxi Zhang, Wenhao Wu, <span class="font-weight-bold"> Yu Lu</span>, Yuxin Song, Kang Rong, Huanjin Yao, Jianbo Zhao, Fanglong Liu, Yifan Sun, Haocheng Feng, Jingdong Wang</br>
                    <i>NeurIPS 2024</i></br>
                                    <a href='https://arxiv.org/pdf/2405.11165'>[Paper]</a> 
                                    <a href='https://github.com/takomc/amp'>[Code]</a> 
                                </p>
                            </div>
                        </div> -->

                        <!-- FlowZero -->
                        <div class="row">
                            <div class="col-sm-3">
                                <img src="images/FlowZero.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">FlowZero: Zero-Shot Text-to-Video Synthesis with LLM-Driven Dynamic Scene Syntax</span></br>
                                    <span class="font-weight-bold"> Yu Lu</span>, Linchao Zhu, Hehe Fan, Yi Yang</br>
                    <i>Arxiv</i></br>
                                    <a href='http://arxiv.org/abs/2311.15813'>[Paper]</a> 
                                    <a href='https://flowzero-video.github.io/'>[Project]</a>
                                    <a href='https://github.com/aniki-ly/FlowZero'>[Code]</a> 
                                </p>
                            </div>
                        </div>

                        <!-- PS-SCL
                        <div class="row">
                            <div class="col-sm-3">
                                <img src="images/T2V.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">Exploiting Unlabeled Videos for Video-Text Retrieval via Pseudo-Supervised Learning</span></br>
                                    <span class="font-weight-bold"> Yu Lu</span>, Ruijie Quan, Linchao Zhu, Yi Yang</br>
                    <i> IEEE Transactions on Image Processing (TIP) </i></br>
                                    <a href='yulu.net.cn'>[Paper]</a> 
                                    <a href='yulu.net.cn'>[code]</a>
                                </p>
                            </div>
                        </div> -->

                        <!-- TIP -->
                        <div class="row">
                            <div class="col-sm-3">
                                <img src="images/TIP.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">Zero-shot Video Grounding with Pseudo Query Lookup and Verification</span></br>
                                    <span class="font-weight-bold"> Yu Lu</span>, Ruijie Quan, Linchao Zhu, Yi Yang</br>
                    <i> IEEE Transactions on Image Processing (TIP) , 2024</i></br>
                                    <a href='https://ieeexplore.ieee.org/document/10440054/authors#authors'>[Paper]</a> 
                                    <a href='https://ieeexplore.ieee.org/document/10440054/authors#authors'>[code]</a>
                                </p>
                            </div>
                        </div>

                        <!-- TMM -->
                        <div class="row">
                            <div class="col-sm-3">
                                <img src="images/TMM.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">Show Me a Video: A Large-Scale Narrated Video Dataset for Coherent Story Illustration</span></br>
                                    <span class="font-weight-bold"> Yu Lu</span>, Feiyue Ni, Haofan Wang, Xiaofeng Guo, Linchao Zhu, Zongxin Yang, Ruihua Song, Lele Cheng, Yi Yang</br>
                    <i>IEEE Transactions on MultiMedia (TMM) , 2023</i></br>
                                    <a href='https://ieeexplore.ieee.org/abstract/document/10195243'>[Paper]</a> 
                                    <a href='https://nfy-dot.github.io/CVSV-dataset/'>[Project]</a>
                                </p>
                            </div>
                        </div>

                        <!-- ECLIP
                        <div class="row">
                            <div class="col-sm-3">
                                <img src="images/EFLIP.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">ECLIP: Efficient Contrastive Language-Image Pretraining via Ensemble Confidence Learning and Masked Language Modeling</span></br>
                                    Jue Wang, Haofan Wang, Weijia Wu, Jincan Deng, <span class="font-weight-bold"> Yu Lu</span>, Xiaofeng Guo, Debing Zhang </br>
                    <i>ICML 2022 Pre-training Workshop</i></br>
                                    <a href='https://openreview.net/pdf?id=5IFFLY4JR24'>[Paper]</a> 
                                    <a href='https://yulu.net.cn/'>[Code]</a>
                                </p>
                            </div>
                        </div> -->

                        <!-- CRIS -->
                        <div class="row">
                            <div class="col-sm-3">
                                <img src="images/CRIS.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">CRIS: CLIP-Driven Referring Image Segmentation</span></br>
                                    Zhaoqing Wang*, <span class="font-weight-bold">Yu Lu*</span>, Qiang Li, Xunqiang Tao, Yandong Guo, MingMing Gong, Tongliang Liu (* means equal contribution)</br>
                    <i>CVPR 2022</i></br>
                                    <a href='https://arxiv.org/abs/2111.15174'>[Paper]</a> 
                                    <a href='https://github.com/DerrickWang005/CRIS.pytorch'>[Code]</a>
                                </p>
                            </div>
                        </div>

                        <!-- GINet
                        <div class="row">
                            <div class="col-sm-3">
                                <img src="images/GINet.png" alt="" class="figure-img img-fluid" alt="Responsive image" style="margin:10px;">
                            </div>
                            <div class="col" style="margin-top: auto; margin-bottom: auto;">
                                <p class="lead">
                                    <span class="font-weight-bold">GINet: Graph Interaction Network for Scene Parsing</span></br>
                                    Tianyi Wu*, <span class="font-weight-bold"> Yu Lu*</span>, Yu Zhu, Chang Zhang, Ming Wu, Zhanyu Ma, Guodong Guo (* means equal contribution)</br>
                                    <i>ECCV 2020</i></br>
                                    <a href='https://arxiv.org/pdf/2009.06160.pdf'>[Paper]</a> 
				    <a href='https://github.com/PaddlePaddle/PaddleSeg'>[Code]</a>
                                </p>
                            </div>
                        </div> -->



                        </div>
            <div>
                <hr>
                <h3 class="subtitle">Professional Activities</h3>

                <div class="row">
                    <div class="col" style="margin-top: auto; margin-bottom: auto;">
                        <p class="lead">
                            <span class="font-weight-bold">Journal Review: </span> <br>
                            TPAMI, TIP, TMM, KBS
                        </p>
                    </div>
                </div>

                <div class="row">
                    <div class="col" style="margin-top: auto; margin-bottom: auto;">
                        <p class="lead">
                            <span class="font-weight-bold">Conference Review: </span> <br>
                            CVPR, ICCV, ECCV, ACL, NeurIPS, ICLR, ICML
                        </p>
                    </div>
                </div>

            </div>


                <div class="col-md-2"></div>
            </div>

    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
</body>

</html>
